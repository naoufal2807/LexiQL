#React0
from typing import Optional, List, Dict
from langgraph.graph import StateGraph, START, END
import requests
import sqlite3
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langgraph.checkpoint.memory import MemorySaver
from langchain.tools import Tool
from pydantic import BaseModel
from langchain.schema import HumanMessage, SystemMessage
from dotenv import load_dotenv
import os
from langchain_core.tools import tool
from langchain_core.messages import AIMessage
from langgraph.prebuilt import create_react_agent
import pprint
load_dotenv()

memory = MemorySaver()


#Defining the State of the graph
class SqlState(BaseModel):
    user_query: Optional[str] = None      # user input Query
    generated_query: Optional[str] = None # SQL generated query
    execution_result: Optional[str] = None # Result  from query execution
    interpretation: Optional[str] = None   # Interpretation of the output
    followup_questions: List[str] = [] # Suggested follow-up questions
    show_query: bool = False  # Wether to display the query 
    
    error_message: Optional[str] = None   # Error Tracking
    conversation_history: List[Dict[str, str]] = [] # Store past interactions  
    schema_info: Dict = None # Store database schema

llm = ChatOpenAI(model="gpt-4o-2024-11-20", api_key=os.getenv("OPENAI_KEY")) 
#print(SqlState)
###########--set up the database 
# Scrapping the data
url = "https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db"

response = requests.get(url)
if response.status_code == 200:
# open a local file in binary write mode 
    with open("Chinook.db", "wb")  as file:
         # Write the content of the response (the file) to the local file
        file.write(response.content)
        print("File downloaded and saved as Chinook.db")
else:
        print(f"Failed to download the file. Status code: {response.status_code}")

    # Setting up the database
db = SQLDatabase.from_uri("sqlite:///Chinook.db")

# get database context
def get_db_schema():
    """Retrieve table names and schema from the database."""
    tables = db.get_usable_table_names()
    schema_info = db.get_table_info()
    return  {"tables_names": tables, "schema": schema_info}
#print(type(get_db_schema()))

# Generate Query tool

def generate_query(state: SqlState) -> SqlState:
    """
    Generate SQL query based on a context, whether the query is already stored in the memory 
    """
    if not state.schema_info:
        state.schema_info = get_db_schema() 
    
    generation_prompt = f"""
    # Task : Generate an SQL query based on the user's natural language request.
    
    ## Context:
    You are an expert in SQL and databases. The user has asked a question in natural language
    , and you must convert it into a valid SQL query.
    the database is provided below. 
    ## Database informations
    ### tables names: You should respect the names of tables mentionned below
    {state.schema_info["tables_names"]}
    ## Database Schema:
    {state.schema_info["schema"]}
    Use this schema to understand the structure of the database, avoid generating arbirtrary names of tables.
    
    ## User Query:
    {state.user_query}
    
    ## Reasoning (Chain of Thought):
    1 **Identify the key entities and attributes** in the user's query that map to the database  {state.schema_info["schema"]} tables and columns.
    2 **Determine the SQL operations** required (e.g., 'SELECT', 'JOIN', 'WHERE', 'GROUP BY').
    3 **Consider filtering conditions** mentioned by the user (e.g., date ranges, specific categories).
    4 **Optimize the query** for efficiency (e.g., avoid unnecessary joins, use indexes).
    
    ## Expected Output:
    - A syntactically correct SQL query.
    - Only use valid table names and column names.
    - Ensure correctness and handle edge cases.
    - Do not assume missing column names-only what exits in the schema.

    
    **SQL Query:**
    
    """

    
    try: 
        response = llm.invoke(generation_prompt)
        if isinstance(response, AIMessage):
            state.generated_query = str(response.content)
        else:
            state.generated_query = response
        
    except Exception as e:
        state.error_message = str(e)
    return state


#state = SqlState(user_query="Give me insights about this database")
#state = SqlState(user_query="Give me insights about artists and albums")
#state = SqlState(user_query="Show me the total sales revenue generated by a specific customer, like Luís Gonçalves", schema_info=get_db_schema())
#custom_  = generate_query(state)
#print(custom_)
#reply = llm.invoke(str(custom_))
#print(reply.content)

# Execute query

def run_smtg(state: SqlState) -> SqlState:
    """To execute a query on the database"""
    result = db.run(state.generated_query)
    state.execution_result = result
    return state
#print(run_smtg(str(reply.content)))

def suggest_follow_up(state: SqlState) -> SqlState:
    """ suggests follow-up questions"""
    if not state.execution_result:
        return state
    suggest_follow_up_prompt = f"""
    Based on the this follwing database {get_db_schema()}following SQL query result:
    {state.execution_result}
    Suggest 3 relevant follow-up questions that leads to natural language queries for the user in order to execute a new query.
    Be careful those queries should be adequate with the informations within the database schema
    """
    result = llm.invoke(suggest_follow_up_prompt).content
    state.followup_questions = result.split("\n")
    return state

#state_1 = SqlState(user_query=state.user_query, generated_query=str(reply.content), execution_result=str(run_smtg(str(reply.content))), schema_info=state.schema_info)

#follow_ups = suggest_follow_up(state_1)
#print(follow_ups.followup_questions)

## Generate interpretation
# interpret result 

def interpret_result(state: SqlState) -> SqlState:
    """Explain the result of executing the query"""
    if not state.execution_result:
        return state  # No result to interpret

    interpretation_prompt = f"""You are expert about the context of this database{state.schema_info} ,based on the user question:{state.user_query} provide explaination to the resulting query execution {state.execution_result}.Focus on providing an easy explaination to the non-technical user without mentionning technical stuff\n Interpretation"""
    result = llm.invoke(interpretation_prompt)
    state.interpretation = result.content
    
    # Store interaction in memory
    state.conversation_history.append({
        "user_query": state.user_query,
        "generated_query": state.generated_query,
        "execution_result": state.execution_result,
        "interpretation": state.interpretation
    })
    #print(state.schema_info)
    return state
    

#final_state = interpret_result(follow_ups)

#print(final_state.interpretation)
# Query validation

def validate_sql(state: SqlState) -> SqlState:
    """Validate the generated SQL query before execution."""
    if not state.generated_query:
        state.error_message = " No SQL query was generated."
        return state
    try:
        # Connect to db
        conn = sqlite3.connect("Chinook.db")
        cursor = conn.cursor()
        
        # Use EXPLAIN QUERY PLAN to validate the SQL without executing it
        if cursor.execute(f"EXPLAIN QUERY PLAN {state.generated_query}") :
            print("cool! it is working ")
            conn.close()
        
        # If no errors, proceed to execution
        state.error_message = None
    except sqlite3.Error as e:
        # Capture SQL syntax or logical errors
        state.error_message = f"SQL Validation: {str(e)}"

#print(validate_sql(final_state))
#### 
tools = [generate_query, validate_sql, interpret_result, suggest_follow_up, run_smtg, get_db_schema]
# Setting up a prompt 

prompt = """You are an AI assistant that helps users interact with databases using SQL. You think step by step before taking any action and follow a structured process.

## Rules:
1. First, analyze the user query, You can acces the database schema to understand the context.
2. Determine if the query requires an SQL operation. Not all operations require generating Sql query.
3. Generate an SQL query based on the database schema.
4. Validate the SQL query before execution.
5. Execute the SQL query.
6. Interpret the results in simple terms for a non-technical user.
7. Suggest follow-up questions to guide further exploration.

## Important :
You should not show the schema of the database to the user It strictly prohibit!

## Format:
- Thought: [Think about the problem]
- Action: [Choose a tool: generate_query, validate_sql, run_smtg, interpret_result, suggest_follow_up]
- Observation: [Analyze the tool output]
- Answer: [Provide the final response if complete in formatted way for the user]


## Example:

**User:** "What are the top-selling products in the last month?"

**AI:**
- Thought: The user wants sales insights. I need to generate an SQL query to get top-selling products from the database.
- Action: Call `generate_query`
- Observation: The generated query is `SELECT product_name, SUM(sales) FROM sales_data WHERE date >= '2024-02-01' GROUP BY product_name ORDER BY SUM(sales) DESC LIMIT 5;`
- Thought: I should validate the SQL before execution.
- Action: Call `validate_sql`
- Observation: The query is valid.
- Thought: Now, I can execute the query.
- Action: Call `run_smtg`
- Observation: The query returned:
"""
graph = create_react_agent(llm, tools=tools, checkpointer=memory,
                        prompt=prompt)
#print(graph.get_graph())
print("--------Welcome----------------")
configuration = {"configurable": {
                        "thread_id": "1" }
                }
while True:
    user_input = input("Please proceed asking a Question ?")
    if user_input in [":q", "exit", "finish", "end"]:
        break
    else:
        inputs = {"messages": [("user", user_input)]}
        for s in graph.stream(inputs, stream_mode="values",config=configuration):
            message = s["messages"][-1]
            if isinstance(message, tuple):
                print(message)
            else:
                
                message.pretty_print()
                
           
